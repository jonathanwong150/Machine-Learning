{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Wong_Jonathan_HW3</h1></center>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Jonathan Wong\n",
    "<br>\n",
    "Github Username: jonathanwong150\n",
    "<br>\n",
    "USC ID: 9171949586"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Time Series Classification Part 1: Feature Creation/Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as bs_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the AReM Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize empty lists to hold test and train data\n",
    "testData = []\n",
    "trainData = []\n",
    "\n",
    "# List of folders in the dataset\n",
    "folders = ['bending1', 'bending2', 'cycling', 'lying', 'sitting', 'standing', 'walking']\n",
    "\n",
    "# Define the path to the dataset\n",
    "dataPath = \"../data/AReM/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Test and Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each folder to read the CSV files\n",
    "for folder in folders:\n",
    "    folderPath = os.path.join(dataPath, folder)\n",
    "    files = os.listdir(folderPath)\n",
    "    \n",
    "    # Sort files to ensure they are in numerical order\n",
    "    files.sort()\n",
    "    \n",
    "    # Decide which files to use for training and testing based on the task description\n",
    "    if folder in ['bending1', 'bending2']:\n",
    "        testFiles = files[:2]\n",
    "        trainFiles = files[2:]\n",
    "    else:\n",
    "        testFiles = files[:3]\n",
    "        trainFiles = files[3:]\n",
    "    \n",
    "    # Read test and train files and append them to respective lists\n",
    "    for file in testFiles:\n",
    "        filePath = os.path.join(folderPath, file)\n",
    "        df = pd.read_csv(filePath, skiprows=4)\n",
    "        df['label'] = folder\n",
    "        testData.append(df)\n",
    "    \n",
    "    for file in trainFiles:\n",
    "        filePath = os.path.join(folderPath, file)\n",
    "        df = pd.read_csv(filePath, skiprows=4)\n",
    "        df['label'] = folder\n",
    "        trainData.append(df)\n",
    "\n",
    "# Convert lists to pandas DataFrames\n",
    "testData = pd.concat(testData, keys=range(len(testData)))\n",
    "trainData = pd.concat(trainData, keys=range(len(trainData)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### i. Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Features:\n",
    "- Minimum\n",
    "- Maximum\n",
    "- Mean\n",
    "- Median\n",
    "- Standard Deviation\n",
    "- Variance\n",
    "- Skewness\n",
    "- Kurtosis\n",
    "- Quartile 1\n",
    "- Quartile 3\n",
    "- IQR\n",
    "\n",
    "Time Series Features:\n",
    "- Autocorrelation\n",
    "- Cross-correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ii. Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Features DataFrame:\n",
      "   min_1  max_1     mean_1  median_1  std_dev_1  1st_quart_1  3rd_quart_1  \\\n",
      "0  37.25  45.00  40.624792     40.50   1.475428      39.2500        42.00   \n",
      "1  38.00  45.67  42.812812     42.50   1.434054      42.0000        43.67   \n",
      "2  12.75  51.00  24.562958     24.25   3.733619      23.1875        26.50   \n",
      "3   0.00  42.75  27.464604     28.00   3.579847      25.5000        30.00   \n",
      "4  24.25  45.00  37.177042     36.25   3.577569      34.5000        40.25   \n",
      "\n",
      "   min_2  max_2    mean_2  ...  1st_quart_5  3rd_quart_5  min_6  max_6  \\\n",
      "0    0.0   1.30  0.358604  ...        33.00        36.00    0.0   1.92   \n",
      "1    0.0   1.22  0.372437  ...        32.00        34.50    0.0   3.11   \n",
      "2    0.0   6.87  0.590833  ...        20.50        27.00    0.0   4.97   \n",
      "3    0.0   7.76  0.449708  ...        15.00        20.75    0.0   6.76   \n",
      "4    0.0   8.58  2.374208  ...        17.95        21.75    0.0   9.34   \n",
      "\n",
      "     mean_6  median_6  std_dev_6  1st_quart_6  3rd_quart_6     label  \n",
      "0  0.570583      0.43   0.582308         0.00         1.30  bending1  \n",
      "1  0.571083      0.43   0.600383         0.00         1.30  bending1  \n",
      "2  0.700188      0.50   0.692997         0.43         0.87  bending2  \n",
      "3  1.122125      0.83   1.011287         0.47         1.30  bending2  \n",
      "4  2.921729      2.50   1.850669         1.50         3.90   cycling  \n",
      "\n",
      "[5 rows x 43 columns]\n",
      "\n",
      "Train Features DataFrame:\n",
      "   min_1  max_1     mean_1  median_1  std_dev_1  1st_quart_1  3rd_quart_1  \\\n",
      "0  35.00  47.40  43.954500     44.33   1.557210        43.00        45.00   \n",
      "1  33.00  47.75  42.179812     43.50   3.666840        39.15        45.00   \n",
      "2  33.00  45.75  41.678063     41.75   2.241152        41.33        42.75   \n",
      "3  37.00  48.00  43.454958     43.25   1.384653        42.50        45.00   \n",
      "4  36.25  48.00  43.969125     44.50   1.616677        43.31        44.67   \n",
      "\n",
      "   min_2  max_2    mean_2  ...  1st_quart_5  3rd_quart_5  min_6  max_6  \\\n",
      "0    0.0   1.70  0.426250  ...      35.3625        36.50    0.0   1.79   \n",
      "1    0.0   3.00  0.696042  ...      30.4575        36.33    0.0   2.18   \n",
      "2    0.0   2.83  0.535979  ...      28.4575        31.25    0.0   1.79   \n",
      "3    0.0   1.58  0.378083  ...      22.2500        24.00    0.0   5.26   \n",
      "4    0.0   1.50  0.413125  ...      20.5000        23.75    0.0   2.96   \n",
      "\n",
      "     mean_6  median_6  std_dev_6  1st_quart_6  3rd_quart_6     label  \n",
      "0  0.493292      0.43   0.512971         0.00         0.94  bending1  \n",
      "1  0.613521      0.50   0.523771         0.00         1.00  bending1  \n",
      "2  0.383292      0.43   0.388759         0.00         0.50  bending1  \n",
      "3  0.679646      0.50   0.621885         0.43         0.87  bending1  \n",
      "4  0.555312      0.49   0.487318         0.00         0.83  bending1  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty lists to hold feature vectors for test and train data\n",
    "testFeatures = []\n",
    "trainFeatures = []\n",
    "\n",
    "# List of columns that represent time series in the dataset\n",
    "seriesCols = ['avg_rss12', 'var_rss12', 'avg_rss13', 'var_rss13', 'avg_rss23', 'var_rss23']\n",
    "\n",
    "# Function to calculate time-domain features for each instance\n",
    "def calculateFeatures(data):\n",
    "    features = []\n",
    "    for column in seriesCols:\n",
    "        minVal = np.min(data[column])\n",
    "        maxVal = np.max(data[column])\n",
    "        meanVal = np.mean(data[column])\n",
    "        medianVal = np.median(data[column])\n",
    "        std = np.std(data[column])\n",
    "        firstQuart = np.percentile(data[column], 25)\n",
    "        thirdQuart = np.percentile(data[column], 75)\n",
    "        \n",
    "        features.extend([minVal, maxVal, meanVal, medianVal, std, firstQuart, thirdQuart])\n",
    "    return features\n",
    "\n",
    "# Loop through each instance in test and train data to calculate features\n",
    "for i in range(len(testData.groupby(level=0))):\n",
    "    instance = testData.loc[i]\n",
    "    features = calculateFeatures(instance)\n",
    "    features.append(instance['label'].iloc[0])\n",
    "    testFeatures.append(features)\n",
    "\n",
    "for i in range(len(trainData.groupby(level=0))):\n",
    "    instance = trainData.loc[i]\n",
    "    features = calculateFeatures(instance)\n",
    "    features.append(instance['label'].iloc[0])\n",
    "    trainFeatures.append(features)\n",
    "\n",
    "# Convert feature lists to DataFrames and add column names\n",
    "featureCols = [f\"{feature}{i+1}\" for i in range(6) for feature in ['min_', 'max_', 'mean_', 'median_', 'std_dev_', '1st_quart_', '3rd_quart_']]\n",
    "featureCols.append('label')\n",
    "\n",
    "testFeatDf = pd.DataFrame(testFeatures, columns=featureCols)\n",
    "trainFeatDf = pd.DataFrame(trainFeatures, columns=featureCols)\n",
    "\n",
    "# Output the new dataset with extracted features\n",
    "print(\"Test Features DataFrame:\")\n",
    "print(testFeatDf.head())\n",
    "\n",
    "print(\"\\nTrain Features DataFrame:\")\n",
    "print(trainFeatDf.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iii. Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t    Standard Deviation   Lower Bound   Upper Bound\n",
      "+=========================+====================+=============+============+\n",
      "| min_avg_rss12           | 9.57               | 8.29        | 10.804      |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| max_avg_rss12           | 4.394              | 3.472       | 5.447       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| mean_avg_rss12          | 5.336              | 4.771       | 5.931       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| median_avg_rss12        | 5.44               | 4.857       | 6.05        |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| std_dev_avg_rss12       | 1.77               | 1.584       | 1.955       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 1st_quart_avg_rss12     | 6.154              | 5.639       | 6.706       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 3rd_quart_avg_rss12     | 5.139              | 4.395       | 5.927       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| min_var_rss12           | 0.0                | 0.0         | 0.0         |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| max_var_rss12           | 5.063              | 4.693       | 5.458       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| mean_var_rss12          | 1.574              | 1.433       | 1.742       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| median_var_rss12        | 1.412              | 1.273       | 1.578       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| std_dev_var_rss12       | 0.883              | 0.821       | 0.96        |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 1st_quart_var_rss12     | 0.946              | 0.85        | 1.055       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 3rd_quart_var_rss12     | 2.125              | 1.942       | 2.345       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| min_avg_rss13           | 2.956              | 2.79        | 3.137       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| max_avg_rss13           | 4.875              | 4.27        | 5.543       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| mean_avg_rss13          | 4.008              | 3.491       | 4.586       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| median_avg_rss13        | 4.036              | 3.5         | 4.621       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| std_dev_avg_rss13       | 0.946              | 0.767       | 1.124       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 1st_quart_avg_rss13     | 4.221              | 3.714       | 4.782       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 3rd_quart_avg_rss13     | 4.172              | 3.627       | 4.769       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| min_var_rss13           | 0.0                | 0.0         | 0.0         |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| max_var_rss13           | 2.184              | 1.992       | 2.379       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| mean_var_rss13          | 1.166              | 1.104       | 1.249       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| median_var_rss13        | 1.146              | 1.084       | 1.231       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| std_dev_var_rss13       | 0.458              | 0.428       | 0.493       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 1st_quart_var_rss13     | 0.844              | 0.792       | 0.906       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 3rd_quart_var_rss13     | 1.553              | 1.471       | 1.663       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| min_avg_rss23           | 6.124              | 4.725       | 7.779       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| max_avg_rss23           | 5.741              | 4.888       | 6.7         |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| mean_avg_rss23          | 5.676              | 4.612       | 6.869       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| median_avg_rss23        | 5.814              | 4.691       | 7.09        |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| std_dev_avg_rss23       | 1.024              | 0.826       | 1.231       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 1st_quart_avg_rss23     | 6.096              | 4.976       | 7.347       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 3rd_quart_avg_rss23     | 5.532              | 4.514       | 6.659       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| min_var_rss23           | 0.046              | 0.013       | 0.091       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| max_var_rss23           | 2.519              | 2.264       | 2.771       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| mean_var_rss23          | 1.155              | 1.088       | 1.243       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| median_var_rss23        | 1.086              | 1.019       | 1.172       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| std_dev_var_rss23       | 0.517              | 0.487       | 0.552       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 1st_quart_var_rss23     | 0.759              | 0.705       | 0.823       |\n",
      "+-------------------------+--------------------+-------------+------------+\n",
      "| 3rd_quart_var_rss23     | 1.524              | 1.437       | 1.635       |\n",
      "+-------------------------+--------------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "combinedDf = pd.concat([trainFeatDf, testFeatDf])\n",
    "\n",
    "# Features to consider\n",
    "domainFeatures = ['min_', 'max_', 'mean_', 'median_', 'std_dev_', '1st_quart_', '3rd_quart_']\n",
    "timeSeries = [str(i) for i in range(1, 7)]\n",
    "\n",
    "# Mapping from your DataFrame column names to desired output names\n",
    "dic = {\n",
    "    \"1\": \"avg_rss12\",\n",
    "    \"2\": \"var_rss12\",\n",
    "    \"3\": \"avg_rss13\",\n",
    "    \"4\": \"var_rss13\",\n",
    "    \"5\": \"avg_rss23\",\n",
    "    \"6\": \"var_rss23\",\n",
    "}\n",
    "\n",
    "# Initialize the results list\n",
    "results = []\n",
    "\n",
    "# Loop over each feature for each time series\n",
    "for series in timeSeries:\n",
    "    for feature in domainFeatures:\n",
    "        colName = f\"{feature}{series}\"\n",
    "        \n",
    "        # Check if the column exists in the DataFrame\n",
    "        if colName in combinedDf.columns:\n",
    "        \n",
    "            # Calculate standard deviation\n",
    "            std = combinedDf[colName].std()\n",
    "\n",
    "            # Bootstrap 90% confidence interval for standard deviation using bootstrapped library\n",
    "            ci = bs.bootstrap(combinedDf[colName].values, stat_func=bs_stats.std, alpha=0.1)\n",
    "            low = ci.lower_bound\n",
    "            high = ci.upper_bound\n",
    "\n",
    "            # Convert to desired names and round to 3 decimal places\n",
    "            mapped_name = f\"{feature}{dic[series]}\"\n",
    "            std = round(std, 3)\n",
    "            low = round(low, 3)\n",
    "            high = round(high, 3)\n",
    "\n",
    "            # Append to results\n",
    "            results.append({\n",
    "                \"Feature Name\": mapped_name,\n",
    "                \"Standard Deviation\": std,\n",
    "                \"Lower Bound\": low,\n",
    "                \"Upper Bound\": high\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Column {colName} not found in DataFrame.\")\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print the results in the desired format\n",
    "print(\"\\t\\t\\t    Standard Deviation   Lower Bound   Upper Bound\")\n",
    "print(\"+=========================+====================+=============+============+\")\n",
    "for index, row in results_df.iterrows():\n",
    "    print(f\"| {row['Feature Name']:<23} | {row['Standard Deviation']:<18} | {row['Lower Bound']:<11} | {row['Upper Bound']:<11} |\")\n",
    "    print(\"+-------------------------+--------------------+-------------+------------+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### iv. Select Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Mean: The best measure of central tendency and used in a lot of our other calculations.\n",
    "- Median: Strong measure of central tendency that is resistant to outliers.\n",
    "- Standard Deviation: Extremely helpful to better understand the spread and estimation of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ISLR 3.7.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cubic regression would most likely have a lower RSS than the linear regression because it could make a tighter fit and is more flexible than the linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) Linear Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression would have a lower RSS as the cubic regression since it will be overfit from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Not Linear Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cubic regression would again have a lower RSS in this case because the more flexible model will be able to align with the data points more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (d) Not Linear Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have enough information to determine which would have a lower RSS. To determine this, we would need to know how far the true relationship is from linear or cubic. Whichever one it is closest to, will have the lower RSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.3 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ISLR 3.7.5 - Extra Practice "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.435px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "3c20c2d94d2527936fe0f3a300eb11db30fed84423423838e2f93b74eb7aaebc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
